{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Description:\n",
    "\n",
    "Use same datasets as Project 2.\n",
    "Run all the models only on 10% data. Use code given in Project 2 for sampling.\n",
    "Preprocess data: Explore data and apply data scaling.\n",
    "Regression Task:\n",
    "\n",
    "Apply any two models with bagging and any two models with pasting.\n",
    "Apply any two models with adaboost boosting\n",
    "Apply one model with gradient boosting\n",
    "Apply PCA on data and then apply all the models in project 2 again on data you get from PCA.\n",
    " Compare your results with results in project 2. You don't need to apply all the models twice.\n",
    " Just copy the result table from project 2, prepare similar table for all the models after PCA and compare both tables. \n",
    " Does PCA help in getting better results?\n",
    "Apply deep learning models covered in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np \n",
    "from scipy import linalg\n",
    "import pylab \n",
    "import scipy.stats as stats \n",
    "from scipy.stats import boxcox\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Imputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import Lasso\n",
    "from  sklearn.linear_model import Ridge\n",
    "from  sklearn.preprocessing  import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from  sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# Importing the data file and renaming the columns** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583249, 78)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the file\n",
    "df=pd.read_csv('Twitter.data')\n",
    "\n",
    "#renaming the columns\n",
    "data_cols=['NCD_0','NCD_1','NCD_2','NCD_3','NCD_4','NCD_5','NCD_6','AI_0','AI_1','AI_2','AI_3','AI_4','AI_5','AI_6','AS(NA)_0','AS(NA)_1','AS(NA)_2','AS(NA)_3','AS(NA)_4','AS(NA)_5','AS(NA)_6','BL_0','BL_1','BL_2','BL_3','BL_4','BL_5','BL_6','NAC_0','NAC_1','NAC_2','NAC_3','NAC_4','NAC_5','NAC_6','AS(NAC)_0','AS(NAC)_1','AS(NAC)_2','AS(NAC)_3','AS(NAC)_4','AS(NAC)_5','AS(NAC)_6','CS_0','CS_1','CS_2','CS_3','CS_4','CS_5','CS_6','AT_0','AT_1','AT_2','AT_3','AT_4','AT_5','AT_6','NA_0','NA_1','NA_2','NA_3','NA_4','NA_5','NA_6',\n",
    "'ADL_0','ADL_1','ADL_2','ADL_3','ADL_4','ADL_5','ADL_6','NAD_0','NAD_1','NAD_2','NAD_3','NAD_4','NAD_5','NAD_6','Target']\n",
    "df.columns=data_cols\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take sample of data for 10% of the total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583249, 76)\n",
      "(583249,)\n"
     ]
    }
   ],
   "source": [
    "X1=df.iloc[:,0:76]\n",
    "y1=df.iloc[:,77]\n",
    "print(X1.shape)\n",
    "print(y1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58325,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Libraries \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Randomizing the dataset and using 10% of the dataset for building models\n",
    "\n",
    "_, X,_, y = train_test_split(X1,y1, shuffle = True, test_size = 0.1)\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree regressor model ,Support vector Regressor , Random forest Regressor has applied with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_clf = DecisionTreeRegressor()\n",
    "\n",
    "bag_clf = BaggingRegressor(dt_clf, n_estimators=50, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score bag_clf: 0.57\n",
      "Test score bag_clf: 0.54\n",
      "Train score dt_clf: 1.00\n",
      "Test score dt_clf: 0.92\n"
     ]
    }
   ],
   "source": [
    "#from  sklearn.metrics import accuracy_score\n",
    "#print(accuracy_score(y_test, y_pred))\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score bag_clf: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score bag_clf: {:.2f}'.format(bag_clf.score(X_test, y_test)))\n",
    "print('Train score dt_clf: {:.2f}'.format(dt_clf.score(X_train, y_train)))\n",
    "print('Test score dt_clf: {:.2f}'.format(dt_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared  score(train) : 0.533\n",
      "R-squared  score(test) : 0.528\n",
      "MAE for train data set : 100.16369720434854\n"
     ]
    }
   ],
   "source": [
    "# creating SVR model with C=1000 and gamma=1\n",
    "svr = SVR( epsilon = 0.01,kernel='linear', C=1, gamma=100)\n",
    "\n",
    "#calculating score and RME\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "print('R-squared  score(train) : {:.3f}'\n",
    "     .format(svr.score(X_train,y_train)))\n",
    "print('R-squared  score(test) : {:.3f}'\n",
    "     .format(svr.score(X_test,y_test)))\n",
    "print('MAE for train data set :', metrics.mean_absolute_error(y_train, svr.predict(X_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared  score(train) : 0.695\n",
      "R-squared  score(test) : 0.696\n",
      "MAE for train data set : 73.42795674608746\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR( epsilon = 0.01,kernel='rbf', C=1000, gamma=0.001)\n",
    "svr_rbf.fit(X_train, y_train)\n",
    "print('R-squared  score(train) : {:.3f}'.format(svr_rbf.score(X_train,y_train)))\n",
    "print('R-squared  score(test) : {:.3f}'     .format(svr_rbf.score(X_test,y_test)))\n",
    "print('MAE for train data set :', metrics.mean_absolute_error(y_train, svr_rbf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared  score(train) : -0.067\n",
      "R-squared  score(test) : -0.056\n",
      "R-squared  score(train) bag_svr_rbf : -0.060\n",
      "R-squared  score(test) bag_svr_rbf: -0.051\n"
     ]
    }
   ],
   "source": [
    "# creating SVR model with C=1000 and gamma=1\n",
    "svr = SVR( epsilon = 0.01,kernel='linear', C=1, gamma=100)\n",
    "bag_svr = BaggingRegressor(svr, n_estimators=5, max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_svr_rbf = BaggingRegressor(svr_rbf, n_estimators=5, max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_svr.fit(X_train, y_train)\n",
    "bag_svr_rbf.fit(X_train, y_train)\n",
    "y_pred = bag_svr.predict(X_test)\n",
    "\n",
    "#calculating score and RME\n",
    "#svr.fit(X_train, y_train)\n",
    "\n",
    "print('R-squared  score(train) : {:.3f}'.format(bag_svr.score(X_train,y_train)))\n",
    "print('R-squared  score(test) : {:.3f}'.format(bag_svr.score(X_test,y_test)))\n",
    "\n",
    "\n",
    "print('R-squared  score(train) bag_svr_rbf : {:.3f}'.format(bag_svr_rbf.score(X_train,y_train)))\n",
    "print('R-squared  score(test) bag_svr_rbf: {:.3f}'.format(bag_svr_rbf.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rnd_clf = RandomForestRegressor(n_estimators=50, max_leaf_nodes=16, n_jobs=-1, random_state=0)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-score on train set: 0.943\n",
      "R-score on train set: 0.951\n"
     ]
    }
   ],
   "source": [
    "print(\"R-score on train set: {:.3f}\".format(rnd_clf.score(X_train, y_train)))\n",
    "print(\"R-score on train set: {:.3f}\".format(rnd_clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree regressor model ,Support vector Regressor , Random forest Regressor has applied with Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_clf = DecisionTreeRegressor()\n",
    "\n",
    "bag_clf = BaggingRegressor(dt_clf, n_estimators=50, max_samples=100, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score bag_clf: 0.57\n",
      "Test score bag_clf: 0.54\n",
      "Train score dt_clf: 1.00\n",
      "Test score dt_clf: 0.91\n"
     ]
    }
   ],
   "source": [
    "#from  sklearn.metrics import accuracy_score\n",
    "#print(accuracy_score(y_test, y_pred))\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score bag_clf: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score bag_clf: {:.2f}'.format(bag_clf.score(X_test, y_test)))\n",
    "print('Train score dt_clf: {:.2f}'.format(dt_clf.score(X_train, y_train)))\n",
    "print('Test score dt_clf: {:.2f}'.format(dt_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared  score(train) : -0.071\n",
      "R-squared  score(test) : -0.060\n",
      "R-squared  score(train) bag_svr_rbf : -0.067\n",
      "R-squared  score(test) bag_svr_rbf: -0.056\n"
     ]
    }
   ],
   "source": [
    "svr = SVR( epsilon = 0.01,kernel='linear', C=1, gamma=100)\n",
    "bag_svr = BaggingRegressor(svr, n_estimators=5, max_samples=100, bootstrap=False, n_jobs=-1)\n",
    "bag_svr_rbf = BaggingRegressor(svr_rbf, n_estimators=5, max_samples=100, bootstrap=False, n_jobs=-1)\n",
    "bag_svr.fit(X_train, y_train)\n",
    "bag_svr_rbf.fit(X_train, y_train)\n",
    "y_pred = bag_svr.predict(X_test)\n",
    "\n",
    "#calculating score and RME\n",
    "#svr.fit(X_train, y_train)\n",
    "\n",
    "print('R-squared  score(train) : {:.3f}'.format(bag_svr.score(X_train,y_train)))\n",
    "print('R-squared  score(test) : {:.3f}'.format(bag_svr.score(X_test,y_test)))\n",
    "\n",
    "\n",
    "print('R-squared  score(train) bag_svr_rbf : {:.3f}'.format(bag_svr_rbf.score(X_train,y_train)))\n",
    "print('R-squared  score(test) bag_svr_rbf: {:.3f}'.format(bag_svr_rbf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.943\n",
      "Accuracy on test set: 0.951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rnd_clf = RandomForestRegressor(n_estimators=50, max_leaf_nodes=16, n_jobs=-1, random_state=0)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(rnd_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rnd_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADABOOSTING  With Decision Tree and Support vector Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared  score(train) : -0.204\n",
      "R-squared  score(test) : 0.023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#X, y = make_moons(n_samples=500, noise=0.30, random_state=0)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "ada_dtreg=AdaBoostRegressor(DecisionTreeRegressor(max_depth=3), n_estimators=50, learning_rate=1.0, loss='linear', random_state=None)\n",
    "#AdaBoostRegressor(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_dtreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('R-squared  score(train) : {:.3f}'.format(ada_dtreg.score(X_train,y_train)))\n",
    "print('R-squared  score(test) : {:.3f}' .format(ada_dtreg.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\amruu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared  score(train) for Random forest regressor : 1.000\n",
      "R-squared  score(test) for Random forest regressor: 0.960\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#X, y = make_moons(n_samples=500, noise=0.30, random_state=0)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "ada_svr =AdaBoostRegressor(RandomForestRegressor(), n_estimators=50, learning_rate=1.0, loss='linear', random_state=None)\n",
    "ada_svr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('R-squared  score(train) for Random forest regressor : {:.3f}'.format(ada_svr.score(X_train,y_train)))\n",
    "print('R-squared  score(test) for Random forest regressor: {:.3f}' .format(ada_svr.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared  score(train) for Random forest regressor : 1.000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared  score(test) for Random forest regressor: 0.960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRADIENT BOOSTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA is applied**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating PCA with 5 variables\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91496289, 0.02055542, 0.01469267])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understand the variation of the PCA\n",
    "pca.components_\n",
    "pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049789011326192734"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understand the total variation contributed by 3 PCA \n",
    "1 - pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 PC components which covers 95 percent of the variations in the 77 columns and hence we can reduce to 3 PC components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to have a sequential index\n",
    "y_PCA = y.reset_index()\n",
    "\n",
    "#creating a data frame for PCA output\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2','principal component 3'])\n",
    "\n",
    "#Concatenating the two data frame \n",
    "finalDf = pd.concat([principalDf, y_PCA], axis = 1)\n",
    "finalDf.shape\n",
    "\n",
    "#creating the Xtemp and y temp to select only the required columns\n",
    "X_temp = finalDf[['principal component 1', 'principal component 2','principal component 3']]\n",
    "y_temp = finalDf['Target']\n",
    "\n",
    "#train and test split \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_temp, y_temp, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a basic linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_score 0.9170171329301148\n",
      "test_score 0.9158811701767884\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train1,y_train1)\n",
    "print('training_score',lreg.score(X_train1, y_train1))\n",
    "print('test_score',lreg.score(X_test1, y_test1))\n",
    "\n",
    "#Pushing the results into another table \n",
    "report_table_n = [['Linear Regression', 'NA',lreg.score(X_train1, y_train1),lreg.score(X_test1, y_test1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9170171329301148, 0.9300714893619608, 0.9401790240697022]\n",
      "[0.9158811701767884, 0.9159094270379954, 0.9217825722727635]\n"
     ]
    }
   ],
   "source": [
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for n in range(1,4):\n",
    "    poly = PolynomialFeatures(n)\n",
    "    X_train_poly = poly.fit_transform(X_train1)\n",
    "    X_test_poly = poly.transform(X_test1)\n",
    "    lreg.fit(X_train_poly, y_train1)\n",
    "    train_score_list.append(lreg.score(X_train_poly, y_train1))\n",
    "    test_score_list.append(lreg.score(X_test_poly, y_test1))\n",
    "    report_table_n = report_table_n + [['Polynomial  Regression', n, lreg.score(X_train_poly, y_train1), lreg.score(X_test_poly, y_test1)]]\n",
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial regression with 2 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R - Score on train set: 0.9300714893619608\n",
      "R - Score on test set: 0.9159094270379954\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X_train_poly = poly.fit_transform(X_train1)\n",
    "X_test_poly = poly.transform(X_test1)\n",
    "lreg.fit(X_train_poly, y_train1)\n",
    "train_score_list=lreg.score(X_train_poly, y_train1)\n",
    "test_score_list=lreg.score(X_test_poly, y_test1)\n",
    "print(\"R - Score on train set:\",train_score_list)\n",
    "print(\"R - Score on test set:\",test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9300714893619608]\n",
      "[0.9159094270379177]\n",
      "[0.9300714893619608, 0.9300714893619608]\n",
      "[0.9159094270379177, 0.9159094270379791]\n",
      "[0.9300714893619608, 0.9300714893619608, 0.9300714893619608]\n",
      "[0.9159094270379177, 0.9159094270379791, 0.9159094270385932]\n",
      "[0.9300714893619608, 0.9300714893619608, 0.9300714893619608, 0.9300714893619608]\n",
      "[0.9159094270379177, 0.9159094270379791, 0.9159094270385932, 0.9159094270447354]\n",
      "[0.9300714893619608, 0.9300714893619608, 0.9300714893619608, 0.9300714893619608, 0.9300714893619608]\n",
      "[0.9159094270379177, 0.9159094270379791, 0.9159094270385932, 0.9159094270447354, 0.9159094271061574]\n"
     ]
    }
   ],
   "source": [
    "#trial for alpha values for polynomial ridge\n",
    "x_range = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_poly = poly.fit_transform(X_train1)\n",
    "X_test_poly = poly.transform(X_test1)\n",
    "    \n",
    "for alpha_1 in x_range: \n",
    "    ridge = Ridge(alpha_1)\n",
    "    ridge.fit(X_train_poly,y_train1)\n",
    "    train_score_list.append(ridge.score(X_train_poly,y_train1))\n",
    "    test_score_list.append(ridge.score(X_test_poly, y_test1))\n",
    "    report_table_n = report_table_n + [['Ridge regression', alpha_1, ridge.score(X_train_poly,y_train1), ridge.score(X_test_poly, y_test1)]]     \n",
    "    print(train_score_list)\n",
    "    print(test_score_list)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression with poly - 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score  poly ridge  0.9300714893619608\n",
      "test_score  poly ridge 0.9159094270379708\n"
     ]
    }
   ],
   "source": [
    "##Polynomial ridge degree 2 with alpha 0.001 as best param \n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_poly = poly.fit_transform(X_train1)\n",
    "X_test_poly = poly.transform(X_test1)\n",
    "linridge = Ridge(alpha =0).fit(X_train_poly, y_train1)\n",
    "r2_train = linridge.score(X_train_poly, y_train1)\n",
    "r2_test = linridge.score(X_test_poly, y_test1)\n",
    "print(\"train_score  poly ridge \",  r2_train)\n",
    "print(\"test_score  poly ridge\",r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso ridge regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression: effect of alpha regularization parameter\n",
      "\n",
      "Alpha = 0.10\n",
      "num abs(coeff) > 1.0: 0,     r-squared training: 0.93, r-squared test: 0.92\n",
      "\n",
      "Alpha = 0.00\n",
      "num abs(coeff) > 1.0: 0,     r-squared training: 0.93, r-squared test: 0.92\n",
      "\n",
      "Alpha = 1.00\n",
      "num abs(coeff) > 1.0: 0,     r-squared training: 0.93, r-squared test: 0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Lasso regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in [0.1,0,1]:\n",
    "    linlasso = Lasso(alpha = this_alpha).fit(X_train_poly, y_train1)\n",
    "    r2_train = linlasso.score(X_train_poly, y_train1)\n",
    "    r2_test = linlasso.score(X_test_poly, y_test1)\n",
    "    num_coeff_bigger = np.sum(abs(linlasso.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "    r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "    .format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n",
    "    report_table_n = report_table_n + [['Lasso regression', this_alpha, linlasso.score(X_train_poly, y_train1), linlasso.score(X_test_poly, y_test1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a KNN regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'MSE')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "for k in range(1,10):\n",
    "    knn_reg = KNeighborsRegressor(k)\n",
    "    knn_reg.fit(X_train1, y_train1)\n",
    "    train_score_array.append(knn_reg.score(X_train1, y_train1))\n",
    "    test_score_array.append(knn_reg.score(X_test1, y_test1))\n",
    "    report_table_n = report_table_n + [['KNN', k, knn_reg.score(X_train1, y_train1), knn_reg.score(X_test1, y_test1)]]\n",
    "    \n",
    "x_axis = range(1,10)\n",
    "plt.plot(x_axis, train_score_array, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, test_score_array, c = 'b', label = 'Test Score')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating SVR model with C=1000 and gamma=1\n",
    "svr = SVR( epsilon = 0.01,kernel='linear', C=1, gamma=100)\n",
    "\n",
    "#calculating score and RME\n",
    "svr.fit(X_train1, y_train1)\n",
    "\n",
    "print('R-squared  score(train) : {:.3f}'\n",
    "     .format(svr.score(X_train1,y_train1)))\n",
    "print('R-squared  score(test) : {:.3f}'\n",
    "     .format(svr.score(X_test1,y_test1)))\n",
    "print('MAE for train data set :', metrics.mean_absolute_error(y_train1, svr.predict(X_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_table = [['Linear Regression', 'NA',0.2585639937596278,0.23331954903976784]]\n",
    "report_table = report_table + [['Polynomial  Regression', 'n(degree) = 3', 0.8424987474651632, 0.8022873007586617]]\n",
    "report_table = report_table + [['Lasso', 'alpha=0.1',0.72 ,0.66]]\n",
    "report_table = report_table + [['SVR', 'epsilon = 0.01 , Gamma=100', 0.8424987625421968, 0.8022873007586617]]\n",
    "report_table = report_table + [['Knn Regressor', 'n=4', 0.724987625421968, 0.7022873007586617]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Model parameter</th>\n",
       "      <th>Train R Score</th>\n",
       "      <th>Test R score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Polynomial  Regression</th>\n",
       "      <td>Polynomial  Regression</td>\n",
       "      <td>n(degree) = 3</td>\n",
       "      <td>0.842499</td>\n",
       "      <td>0.802287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>SVR</td>\n",
       "      <td>epsilon = 0.01 , Gamma=100</td>\n",
       "      <td>0.842499</td>\n",
       "      <td>0.802287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn Regressor</th>\n",
       "      <td>Knn Regressor</td>\n",
       "      <td>n=4</td>\n",
       "      <td>0.724988</td>\n",
       "      <td>0.702287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>alpha=0.1</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.258564</td>\n",
       "      <td>0.233320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model name             Model parameter  \\\n",
       "Model name                                                                   \n",
       "Polynomial  Regression  Polynomial  Regression               n(degree) = 3   \n",
       "SVR                                        SVR  epsilon = 0.01 , Gamma=100   \n",
       "Knn Regressor                    Knn Regressor                         n=4   \n",
       "Lasso                                    Lasso                   alpha=0.1   \n",
       "Linear Regression            Linear Regression                          NA   \n",
       "\n",
       "                        Train R Score  Test R score  \n",
       "Model name                                           \n",
       "Polynomial  Regression       0.842499      0.802287  \n",
       "SVR                          0.842499      0.802287  \n",
       "Knn Regressor                0.724988      0.702287  \n",
       "Lasso                        0.720000      0.660000  \n",
       "Linear Regression            0.258564      0.233320  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = pd.DataFrame(report_table,columns = ['Model name', 'Model parameter', 'Train R Score', 'Test R score'])\n",
    "report.index = report['Model name']\n",
    "report.sort_values(by='Test R score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Model parameter</th>\n",
       "      <th>Train R Score</th>\n",
       "      <th>Test R score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Polynomial  Regression</th>\n",
       "      <td>Polynomial  Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.940179</td>\n",
       "      <td>0.921783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.938751</td>\n",
       "      <td>0.919846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943807</td>\n",
       "      <td>0.918127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso regression</th>\n",
       "      <td>Lasso regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso regression</th>\n",
       "      <td>Lasso regression</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge regression</th>\n",
       "      <td>Ridge regression</td>\n",
       "      <td>100</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge regression</th>\n",
       "      <td>Ridge regression</td>\n",
       "      <td>10</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge regression</th>\n",
       "      <td>Ridge regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial  Regression</th>\n",
       "      <td>Polynomial  Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge regression</th>\n",
       "      <td>Ridge regression</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge regression</th>\n",
       "      <td>Ridge regression</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso regression</th>\n",
       "      <td>Lasso regression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>0.915909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.917017</td>\n",
       "      <td>0.915881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial  Regression</th>\n",
       "      <td>Polynomial  Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917017</td>\n",
       "      <td>0.915881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.934185</td>\n",
       "      <td>0.912077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.929116</td>\n",
       "      <td>0.911212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.947818</td>\n",
       "      <td>0.911113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.925409</td>\n",
       "      <td>0.910865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.955898</td>\n",
       "      <td>0.905195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.967077</td>\n",
       "      <td>0.893237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model name Model parameter  Train R Score  \\\n",
       "Model name                                                                      \n",
       "Polynomial  Regression  Polynomial  Regression               3       0.940179   \n",
       "KNN                                        KNN               6       0.938751   \n",
       "KNN                                        KNN               5       0.943807   \n",
       "Lasso regression              Lasso regression               1       0.930071   \n",
       "Lasso regression              Lasso regression             0.1       0.930071   \n",
       "Ridge regression              Ridge regression             100       0.930071   \n",
       "Ridge regression              Ridge regression              10       0.930071   \n",
       "Ridge regression              Ridge regression               1       0.930071   \n",
       "Polynomial  Regression  Polynomial  Regression               2       0.930071   \n",
       "Ridge regression              Ridge regression             0.1       0.930071   \n",
       "Ridge regression              Ridge regression            0.01       0.930071   \n",
       "Lasso regression              Lasso regression               0       0.930071   \n",
       "Linear Regression            Linear Regression              NA       0.917017   \n",
       "Polynomial  Regression  Polynomial  Regression               1       0.917017   \n",
       "KNN                                        KNN               7       0.934185   \n",
       "KNN                                        KNN               8       0.929116   \n",
       "KNN                                        KNN               4       0.947818   \n",
       "KNN                                        KNN               9       0.925409   \n",
       "KNN                                        KNN               3       0.955898   \n",
       "KNN                                        KNN               2       0.967077   \n",
       "KNN                                        KNN               1       1.000000   \n",
       "\n",
       "                        Test R score  \n",
       "Model name                            \n",
       "Polynomial  Regression      0.921783  \n",
       "KNN                         0.919846  \n",
       "KNN                         0.918127  \n",
       "Lasso regression            0.915910  \n",
       "Lasso regression            0.915909  \n",
       "Ridge regression            0.915909  \n",
       "Ridge regression            0.915909  \n",
       "Ridge regression            0.915909  \n",
       "Polynomial  Regression      0.915909  \n",
       "Ridge regression            0.915909  \n",
       "Ridge regression            0.915909  \n",
       "Lasso regression            0.915909  \n",
       "Linear Regression           0.915881  \n",
       "Polynomial  Regression      0.915881  \n",
       "KNN                         0.912077  \n",
       "KNN                         0.911212  \n",
       "KNN                         0.911113  \n",
       "KNN                         0.910865  \n",
       "KNN                         0.905195  \n",
       "KNN                         0.893237  \n",
       "KNN                         0.862817  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = pd.DataFrame(report_table_n,columns = ['Model name', 'Model parameter', 'Train R Score', 'Test R score'])\n",
    "report.index = report['Model name']\n",
    "report.sort_values(by='Test R score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of PCA is better than the test R-Score value we obtained in project 2 for the model polynomial regression and hence\n",
    "the best model is polynomial regression with PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-199f7040c725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#fix random seed for reproducibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "#fix random seed for reproducibility\n",
    "numpy.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='sgd' , metrics = ['mse'])\n",
    "\n",
    "#Fit the model \n",
    "model.fit(X_train, y_train, epochs = 50, batch_size = 20)\n",
    "\n",
    "#Evaluate the model\n",
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "#Training and testing score \n",
    "from sklearn.metrics import r2_score, recall_score, precision_score\n",
    "\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "print('Train score: {:.2f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test score: {:.2f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
