{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0mT89BjNZWfg"
   },
   "source": [
    "**Importing necessary functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeXAnVAsXfib"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np \n",
    "import pylab \n",
    "import scipy.stats as stats \n",
    "from scipy.stats import boxcox\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Imputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import Lasso\n",
    "from  sklearn.linear_model import Ridge\n",
    "from  sklearn.preprocessing  import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G2sS3IedaMdI"
   },
   "source": [
    "**# Importing the data file and renaming the columns** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ag6R45FBXqCy",
    "outputId": "986bc3ea-1b60-4247-8971-d54f7b0a68b8"
   },
   "outputs": [],
   "source": [
    "#reading the file\n",
    "df=pd.read_csv('Twitter.data')\n",
    "\n",
    "#renaming the columns\n",
    "data_cols=['NCD_0','NCD_1','NCD_2','NCD_3','NCD_4','NCD_5','NCD_6','AI_0','AI_1','AI_2','AI_3','AI_4','AI_5','AI_6','AS(NA)_0','AS(NA)_1','AS(NA)_2','AS(NA)_3','AS(NA)_4','AS(NA)_5','AS(NA)_6','BL_0','BL_1','BL_2','BL_3','BL_4','BL_5','BL_6','NAC_0','NAC_1','NAC_2','NAC_3','NAC_4','NAC_5','NAC_6','AS(NAC)_0','AS(NAC)_1','AS(NAC)_2','AS(NAC)_3','AS(NAC)_4','AS(NAC)_5','AS(NAC)_6','CS_0','CS_1','CS_2','CS_3','CS_4','CS_5','CS_6','AT_0','AT_1','AT_2','AT_3','AT_4','AT_5','AT_6','NA_0','NA_1','NA_2','NA_3','NA_4','NA_5','NA_6',\n",
    "'ADL_0','ADL_1','ADL_2','ADL_3','ADL_4','ADL_5','ADL_6','NAD_0','NAD_1','NAD_2','NAD_3','NAD_4','NAD_5','NAD_6','Target']\n",
    "df.columns=data_cols\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hyq-w-lwAONK"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aX8XFvsnap0z"
   },
   "source": [
    "**Data Leakage , the correlation between target and features are evaluated and Highly correlated values are chosen .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Z215G_G0n6e"
   },
   "outputs": [],
   "source": [
    "#selecting the required columns\n",
    "columns = ['NCD_0','NCD_1','NCD_2','NCD_3','NCD_4','NCD_5','NCD_6','AI_0','AI_1','AI_2','AI_3','AI_4','AI_5','AI_6','AS(NA)_0','AS(NA)_1','AS(NA)_2','AS(NA)_3','AS(NA)_4','AS(NA)_5','AS(NA)_6','BL_0','BL_1','BL_2','BL_3','BL_4','BL_5','BL_6','NAC_0','NAC_1','NAC_2','NAC_3','NAC_4','NAC_5','NAC_6','AS(NAC)_0','AS(NAC)_1','AS(NAC)_2','AS(NAC)_3','AS(NAC)_4','AS(NAC)_5','AS(NAC)_6','CS_0','CS_1','CS_2','CS_3','CS_4','CS_5','CS_6','AT_0','AT_1','AT_2','AT_3','AT_4','AT_5','AT_6','NA_0','NA_1','NA_2','NA_3','NA_4','NA_5','NA_6',\n",
    "'ADL_0','ADL_1','ADL_2','ADL_3','ADL_4','ADL_5','ADL_6','NAD_0','NAD_1','NAD_2','NAD_3','NAD_4','NAD_5','NAD_6']\n",
    "\n",
    "for name in columns:\n",
    "    print(name,np.corrcoef(df[name],df['Target'])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQOcPTaza3Zh"
   },
   "source": [
    "**The following features and hence chose to proceed further . \n",
    "But the other columns are ignored . **  'AC_1','NAC_2','NAC_3','NAC_4','NAC_5','NAC_6','AS(NAC)_0','AS(NAC)_1','AS(NAC)_2','AS(NAC)_3','AS(NAC)_4','AS(NAC)_5','AS(NAC)_6','CS_0','CS_1','CS_2','CS_3','CS_4','CS_5','CS_6','NA_0','NA_1','NA_2','NA_3','NA_4','NA_5','NA_6','NAD_0','NAD_1','NAD_2','NAD_3','NAD_4','NAD_5','NAD_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_oHieurGavHz"
   },
   "outputs": [],
   "source": [
    "['AI_0','AI_1','AI_2','AI_3','AI_4','AI_5','AI_6','AS(NA)_0','AS(NA)_1','AS(NA)_2','AS(NA)_3','AS(NA)_4','AS(NA)_5','AS(NA)_6','NAC_0','NAC_1','NAC_2','NAC_3','NAC_4','NAC_5','NAC_6','AS(NAC)_0','AS(NAC)_1','AS(NAC)_2','AS(NAC)_3','AS(NAC)_4','AS(NAC)_5','AS(NAC)_6','CS_0','CS_1','CS_2','CS_3','CS_4','CS_5','CS_6','NA_0','NA_1','NA_2','NA_3','NA_4','NA_5','NA_6','NAD_0','NAD_1','NAD_2','NAD_3','NAD_4','NAD_5','NAD_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WswM447bBRh"
   },
   "source": [
    "**To remove the multicollinearity between variables - we are calculating the VIF for each variable - threshold < 5 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ER2nCVrPa9Ez"
   },
   "outputs": [],
   "source": [
    "#Creating a data frame with just the variables which are correlated to Target\n",
    "#extracting the features as X and target as Y \n",
    "X = df[['AI_0','AI_1','AI_2','AI_3','AI_4','AI_5','AI_6','AS(NA)_0','AS(NA)_1','AS(NA)_2','AS(NA)_3','AS(NA)_4','AS(NA)_5','AS(NA)_6','NAC_0','NAC_1','NAC_2','NAC_3','NAC_4','NAC_5','NAC_6','AS(NAC)_0','AS(NAC)_1','AS(NAC)_2','AS(NAC)_3','AS(NAC)_4','AS(NAC)_5','AS(NAC)_6','CS_0','CS_1','CS_2','CS_3','CS_4','CS_5','CS_6','NA_0','NA_1','NA_2','NA_3','NA_4','NA_5','NA_6','NAD_0','NAD_1','NAD_2','NAD_3','NAD_4','NAD_5','NAD_6','Target']]\n",
    "y = X.pop('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymQ5QltPbE6w"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vm48LV0lbK9i"
   },
   "outputs": [],
   "source": [
    "#Creating a class which can calculate VIF for each variable\n",
    "class ReduceVIF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, thresh=5.0, impute=True, impute_strategy='median'):\n",
    "        # From looking at documentation, values between 5 and 10 are \"okay\".\n",
    "        # Above 10 is too high and so should be removed.\n",
    "        self.thresh = thresh\n",
    "        \n",
    "        # The statsmodel function will fail with NaN values, as such we have to impute them.\n",
    "        # By default we impute using the median value.\n",
    "        # This imputation could be taken out and added as part of an sklearn Pipeline.\n",
    "        if impute:\n",
    "            self.imputer = Imputer(strategy=impute_strategy)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print('ReduceVIF fit')\n",
    "        if hasattr(self, 'imputer'):\n",
    "            self.imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print('ReduceVIF transform')\n",
    "        columns = X.columns.tolist()\n",
    "        if hasattr(self, 'imputer'):\n",
    "            X = pd.DataFrame(self.imputer.transform(X), columns=columns)\n",
    "        return ReduceVIF.calculate_vif(X, self.thresh)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_vif(X, thresh=5.0):\n",
    "        # Taken from https://stats.stackexchange.com/a/253620/53565 and modified\n",
    "        dropped=True\n",
    "        while dropped:\n",
    "            variables = X.columns\n",
    "            dropped = False\n",
    "            vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n",
    "            \n",
    "            max_vif = max(vif)\n",
    "            if max_vif > thresh:\n",
    "                maxloc = vif.index(max_vif)\n",
    "                print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n",
    "                X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n",
    "                dropped=True\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yri8vwiKbS65"
   },
   "outputs": [],
   "source": [
    "transformer = ReduceVIF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eex53JzSbWaN"
   },
   "outputs": [],
   "source": [
    "#Analyzing which variables to drop - to remove multicollinearity\n",
    "X = transformer.fit_transform(X[X.columns[-49:]], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sDx1aWM4_4r"
   },
   "source": [
    "Finally decided to remove variables which are more than VIF 10 - Based on commonly used assumption and the below columns are chosen for further steps. \n",
    "\n",
    "To avoid overfitting and train regression models better with data values better  these steps has been carried out. ['AI_0','AI_1','AI_2','AI_4','AI_5','AI_6','AS(NA)_3','AS(NAC)_0','AS(NAC)_2','CS_0','CS_1','NAD_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSc7K_N4bcKj"
   },
   "outputs": [],
   "source": [
    "['AI_0','AI_1','AI_2','AI_4','AI_5','AI_6','AS(NA)_3','AS(NAC)_0','AS(NAC)_2','CS_0','CS_1','NAD_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfrXb-Xuc9jS"
   },
   "source": [
    "**Drawing distributions for each feature of AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zc1jrqVp6Yt2"
   },
   "outputs": [],
   "source": [
    "data_cols=['AI_0','AI_1','AI_2','AI_3','AI_4','AI_5','AI_6']\n",
    "\n",
    "for name in data_cols:\n",
    "    print(name)\n",
    "    x = df[name]\n",
    "    plt.hist(x, bins=100)\n",
    "    plt.ylabel('No of times')\n",
    "    plt.show()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4S5TGtaLdFjl"
   },
   "source": [
    "**Since the columns is not normally distrubuted, we are trying various combinations of log,sqrt and box cox to reduce skewness **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnkOQ3L9dE1h"
   },
   "outputs": [],
   "source": [
    "#understanding the skewness of AI_0\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import skew\n",
    "import math\n",
    "\n",
    "skness = skew(df['AI_0'])\n",
    "print(\"skness\",skness)\n",
    "\n",
    "x11=np.sqrt(df['AI_0'])\n",
    "skness_sqrt = skew(x11)\n",
    "print(\"skness_sqrt\",skness_sqrt)\n",
    "\n",
    "x12 = (x11+1).apply(np.log)\n",
    "skness_sqrt_log = skew(x12)\n",
    "print(\"skness_sqrt_log\",skness_sqrt_log) \n",
    "\n",
    "bxcx = boxcox(x12+1)[0] #---- we are selecting this transformation\n",
    "skness_sqrt_log_bxcx = skew(bxcx)\n",
    "print(\"skness_sqrt_log_bxcx\",skness_sqrt_log_bxcx)\n",
    "\n",
    "x = (df['AI_0']+1).apply(np.log)\n",
    "skness_log = skew(x11)\n",
    "print(\"skness_log\",skness_log)\n",
    "\n",
    "x11=np.sqrt(x)\n",
    "skness_log_sqrt = skew(x11)\n",
    "print(\"skness_log_sqrt\",skness_log_sqrt)\n",
    "\n",
    "bxcx = boxcox(x11+1)[0]\n",
    "skness_log_sqrt_bxcx = skew(bxcx)\n",
    "print(\"skness_log_sqrt_bxcx\",skness_log_sqrt_bxcx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_PfqImBPdNJR"
   },
   "source": [
    "**Now applying the same transformation techniques(sqrt, log and box cox) for other AI columns i.e. from AI_1 to AI_6 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMDRv3tEdB-D"
   },
   "outputs": [],
   "source": [
    "data_cols_AI=['AI_0','AI_1','AI_2','AI_3','AI_4','AI_5','AI_6']\n",
    "\n",
    "for name in data_cols_AI:\n",
    "    print(name)\n",
    "    from scipy.stats import boxcox\n",
    "    from scipy.stats import skew\n",
    "    import math\n",
    "\n",
    "    skness = skew(df[name])\n",
    "    print(\"skness\",skness)\n",
    "\n",
    "    x11=np.sqrt(df[name])\n",
    "    skness_sqrt = skew(x11)\n",
    "    print(\"skness_sqrt\",skness_sqrt)\n",
    "\n",
    "    x12 = (x11+1).apply(np.log)\n",
    "    skness_sqrt_log = skew(x12)\n",
    "    print(\"skness_sqrt_log\",skness_sqrt_log) #---- we are selecting this transformation\n",
    "    \n",
    "    bxcx = boxcox(x12+1)[0] #---- we are selecting this transformation\n",
    "    skness_sqrt_log_bxcx = skew(bxcx)\n",
    "    print(\"skness_sqrt_log_bxcx\",skness_sqrt_log_bxcx)   \n",
    "\n",
    "    #printing the q-q plot and histogram for the selected transformation - sqrt_log\n",
    "    #Checking the normality by drawing a Q-Q plot on transformed data \n",
    "    print(\"Q-Q Plot for the transformed column\")\n",
    "    stats.probplot(bxcx, dist=\"norm\", plot=pylab)\n",
    "    pylab.show()\n",
    "\n",
    "    #Checking the histogram of the untransformed data \n",
    "    print(\"histogram for the transformed data\")\n",
    "    plt.hist(bxcx, bins='auto')\n",
    "    plt.ylabel('No of times')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC03XWKddZTs"
   },
   "source": [
    "**Drawing distributions for each variable of  AS(NA)_3 ,AS(NAC)_0 ,AS(NAC)_2 ,CS_0 ,CS_1 ,NAD_3 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARjXqWY-g5ab"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "from scipy.stats import skew\n",
    "import math\n",
    "data_cols=['AS(NA)_3','AS(NAC)_0','AS(NAC)_2','CS_0','CS_1','NAD_3']\n",
    "#data_cols_AI=['AI_0','AI_1','AI_2','AI_3','AI_4','AI_5','AI_6']\n",
    "\n",
    "for name in data_cols:\n",
    "    print(name)\n",
    "    from scipy.stats import boxcox\n",
    "    from scipy.stats import skew\n",
    "    import math\n",
    "\n",
    "    skness = skew(df[name])\n",
    "    print(\"skness\",skness)\n",
    "\n",
    "    x11=np.sqrt(df[name])\n",
    "    skness_sqrt = skew(x11)\n",
    "    print(\"skness_sqrt\",skness_sqrt)\n",
    "\n",
    "    x12 = (x11+1).apply(np.log)\n",
    "    skness_sqrt_log = skew(x12)\n",
    "    print(\"skness_sqrt_log\",skness_sqrt_log) #---- we are selecting this transformation\n",
    "    \n",
    "    bxcx = boxcox(x12+1)[0] #---- we are selecting this transformation\n",
    "    skness_sqrt_log_bxcx = skew(bxcx)\n",
    "    print(\"skness_sqrt_log_bxcx\",skness_sqrt_log_bxcx)   \n",
    "\n",
    "    #printing the q-q plot and histogram for the selected transformation - sqrt_log\n",
    "    #Checking the normality by drawing a Q-Q plot on transformed data \n",
    "    print(\"Q-Q Plot for the transformed column\")\n",
    "    stats.probplot(bxcx, dist=\"norm\", plot=pylab)\n",
    "    pylab.show()\n",
    "\n",
    "    #Checking the histogram of the untransformed data \n",
    "    print(\"histogram for the transformed data\")\n",
    "    plt.hist(bxcx, bins='auto')\n",
    "    plt.ylabel('No of times')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnfy7YTL9q7u"
   },
   "source": [
    "After determining the type of transformation  , lets apply that transformed value in the data frame \n",
    "\n",
    "The sqrt-log transformation is applied to features : NCD_1,NCD_2,NCD_3,'AI_1','AI_2','AI_3'\n",
    "\n",
    "The square root , log transformation and boxcox transformations is applied to the following features:    NCD_0,NCD_4,NCD_5,NCD_6,'AI_0','AI_4','AI_5','AI_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYMSb14adjEe"
   },
   "outputs": [],
   "source": [
    "sqrt_log_bxcx=['AI_0','AI_1','AI_5','AI_6','AS(NA)_3','AS(NAC)_0','AS(NAC)_2']\n",
    "sqrt_log =['AI_2','AI_3','AI_4','NAD_3']\n",
    "td=df\n",
    "for names1 in sqrt_log_bxcx: \n",
    "   #td[names1]=boxcox(np.sqrt(df[names1]).apply(np.log)+1)[0] \n",
    "    x=np.sqrt(df[names1])\n",
    "    x11 = (x+1).apply(np.log)\n",
    "    x12 = boxcox(x11+1)[0]\n",
    "    td[names1] = x12\n",
    "    \n",
    "for names2 in sqrt_log: \n",
    "    x2=np.sqrt(df[names2])\n",
    "    x21 = (x2+1).apply(np.log)\n",
    "    td[names2] = x21  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dlKKJfaddR-"
   },
   "outputs": [],
   "source": [
    "x_train=td[['AI_2','AI_3','AI_4','NAD_3','AI_0','AI_1','AI_5','AI_6','AS(NA)_3','AS(NAC)_0','AS(NAC)_2']]\n",
    "y=td['Target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kT9Tc8nx_fof"
   },
   "source": [
    "Performing the testing Train split for all the data values for the transformed columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myB1J_bodh5K"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train,y, random_state = 0,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ql7k48tqAwkx"
   },
   "source": [
    "After preforming scaling of data and running the models , it was observed that there was not much of impact in results due to scaling and the code has been commented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvlwsyPMAlQO"
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#X_train = scaler.fit_transform(X_train_unscaled)\n",
    "#X_test = scaler.transform(X_text_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "84XAHJqUAoQC",
    "outputId": "3ca7e529-a064-4638-b69a-7325515a23d7"
   },
   "outputs": [],
   "source": [
    "\n",
    "lreg = LinearRegression()\n",
    "a=lreg.fit(X_train, y_train)\n",
    "print('training_score',lreg.score(X_train, y_train))\n",
    "print('test_score',lreg.score(X_test, y_test))\n",
    "#a.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzZB8LFHzhUR"
   },
   "source": [
    "#Polynomial  Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yZPrAN0RyLXZ",
    "outputId": "25dddd16-5aec-491a-e1cf-c2a23c5b9c2c"
   },
   "outputs": [],
   "source": [
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for n in range(1,4):\n",
    "    poly = PolynomialFeatures(n)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    lreg.fit(X_train_poly, y_train)\n",
    "    train_score_list.append(lreg.score(X_train_poly, y_train))\n",
    "    test_score_list.append(lreg.score(X_test_poly, y_test))\n",
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "gZXtYN4M1DVZ",
    "outputId": "a35cd47a-c516-4264-80b7-6ce447600c1f"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x_axis = range(1,4)\n",
    "plt.plot(x_axis, train_score_list, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, test_score_list, c = 'b', label = 'Test Score')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "k4o_Ud7f4p3c",
    "outputId": "5dd2fc66-8e50-42b8-d33d-ecf12d05e54c"
   },
   "outputs": [],
   "source": [
    "#trial for alpha values for polynomial ridge\n",
    "x_range = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "    \n",
    "for alpha_1 in x_range: \n",
    "    ridge = Ridge(alpha_1)\n",
    "    ridge.fit(X_train_poly,y_train)\n",
    "    train_score_list.append(ridge.score(X_train_poly,y_train))\n",
    "    test_score_list.append(ridge.score(X_test_poly, y_test))\n",
    "       \n",
    "    print(train_score_list)\n",
    "    print(test_score_list)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "5GrQcoJs9dy3",
    "outputId": "3441200e-b612-493a-ec26-0c30824c2b0e"
   },
   "outputs": [],
   "source": [
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in [0, 1, 10]:\n",
    "    poly = PolynomialFeatures(3)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    linridge = Ridge(alpha = this_alpha).fit(X_train_poly, y_train)\n",
    "    r2_train = linridge.score(X_train_poly, y_train)\n",
    "    r2_test = linridge.score(X_test_poly, y_test)\n",
    "    print(\"train_score  poly ridge\",  r2_train)\n",
    "    print(\"test_score  poly ridge\",r2_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zN_wKhS1j22"
   },
   "outputs": [],
   "source": [
    "# finding best alpha by gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': [ 0.001,0.01,0.1,0,1]}\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_poly, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "grid_search= GridSearchCV(ridge(),param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wbgUDRXDCvOS"
   },
   "outputs": [],
   "source": [
    "##Polynomial ridge degree 2 with alpha 0.001 as best param \n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "linridge = Ridge(alpha =0).fit(X_train_poly, y_train)\n",
    "r2_train = linridge.score(X_train_poly, y_train)\n",
    "r2_test = linridge.score(X_test_poly, y_test)\n",
    "print(\"train_score  poly ridge \",  r2_train)\n",
    "print(\"test_score  poly ridge\",r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBHlJuA1DhAo"
   },
   "outputs": [],
   "source": [
    "print('Lasso regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in [0.1,0,1]:\n",
    "    linlasso = Lasso(alpha = this_alpha).fit(X_train_poly, y_train)\n",
    "    r2_train = linlasso.score(X_train_poly, y_train)\n",
    "    r2_test = linlasso.score(X_test_poly, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linlasso.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "    r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "    .format(this_alpha, num_coeff_bigger, r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OXgn4zhH7Sa4",
    "outputId": "e0000eef-3b7c-4cc3-b6b1-dc43f5c01705"
   },
   "outputs": [],
   "source": [
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "for k in range(1,10):\n",
    "    knn_reg = KNeighborsRegressor(k)\n",
    "    knn_reg.fit(X_train, y_train)\n",
    "    train_score_array.append(knn_reg.score(X_train, y_train))\n",
    "    test_score_array.append(knn_reg.score(X_test, y_test))\n",
    "\n",
    "x_axis = range(1,10)\n",
    "plt.plot(x_axis, train_score_array, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, test_score_array, c = 'b', label = 'Test Score')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#N neighbors with 2 value is best param in knn regression\n",
    "knnreg = KNeighborsRegressor(n_neighbors = 2).fit(X_train, y_train)\n",
    "print('R-squared test score: {:.3f}'.format(knnreg.score(X_test, y_test)))\n",
    "print('R-squared train score: {:.3f}'.format(knnreg.score(X_train, y_train)))\n",
    "#print('MAE for train data set :', metrics.mean_absolute_error(y_train, linridge.predict(X_train)))\n",
    "#x_pred=knnreg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "MBcNQ5rh3JLg",
    "outputId": "10c162b0-b541-4e92-df84-d21551b2d238"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#x_axis = range(1,4)\n",
    "plt.scatter(x_pred, y_test)\n",
    "#plt.scatter(y_test, c = 'b')\n",
    "plt.xlabel('Predicted values of number of active discussions' )\n",
    "plt.ylabel('actual  Buzz number of active discussions')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating SVR model with C=1000 and gamma=1\n",
    "svr = SVR( epsilon = 0.01,kernel='linear', C=1, gamma=100)\n",
    "#svr_rbf = SVR( epsilon = 0.01,kernel='rbf', C=1000, gamma=0.001)\n",
    "\n",
    "#calculating score and RME\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "print('R-squared  score(train) : {:.3f}'\n",
    "     .format(svr.score(X_train,y_train)))\n",
    "print('R-squared  score(test) : {:.3f}'\n",
    "     .format(svr.score(X_test,y_test)))\n",
    "print('MAE for train data set :', metrics.mean_absolute_error(y_train, svr.predict(X_train)))\n",
    "svr_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('R-squared  score(train) : {:.3f}'\n",
    "     .format(svr_rbf.score(X_train_scaled,y_train)))\n",
    "print('R-squared  score(test) : {:.3f}'\n",
    "     .format(svr_rbf.score(X_test,y_test)))\n",
    "print('MAE for train data set :', metrics.mean_absolute_error(y_train, svr_rbf.predict(X_train_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models where executed and the best model is polynomial ridge with R square value for training is 0.8424 and R score for testing score is 0.80 and The best parameter for alpha is 0 ."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "twitter_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
